%%
% TUM Corporate Design LaTeX Templates
% Based on the templates from https://www.tum.de/cd
%
% Feel free to join development on
% https://gitlab.lrz.de/tum-templates/templates
% and/or to create an issue in case of trouble.
%
% tum-article class for scientific articles, reports, exercise sheets, ...
%
%%

\documentclass[twocolumn]{tum-article}
%\documentclass[twocolumn, german]{tum-article}
%\documentclass[times, twocolumn]{tum-article}
%\documentclass[times]{tum-article}
%\documentclass{tum-article}

\usepackage{lipsum}

\title{Modifying the Writing Style in Goal-Oriented Dialog Generation}
\author{Fabian Bell\authormark{1,\Letter}\orcid{0000-0001-9595-4226},
  Monika Wintergerst\authormark{1}\orcid{0000-0002-9244-5431}}

% if too long for running head
\titlerunning{TUM Article}
\authorrunning{Author 1 et al.}

\email{fabian.bell@tum.de}

\affil[1]{Department of Informatics, Technical University of Munich (TUM),
  Boltzmannstr. 3, 85748 Garching, Germany}

\date{Received: 10 August 2017 / Accepted: 02 Februar 2018\thanks{This is a
    post-peer-review, pre-copyedit version of an article published in Fancy
    Journal. The final authenticated version is available online at:
    \url{http://dx.doi.org/}}}

\begin{document}

\maketitle

\begin{abstract}
In this work we present a combination of end-to-end goal oriented dialogue generation with style adaptive response generation. We show that a style extractor like TextSETTR \cite{riley2020textsettr} and be fused with a end-to-end dialogue generator like Soloist \cite{peng2020soloist} in order to build a dialogue agent that is able to adapt the users writing style.  
\end{abstract}

\section{Introduction}

Dialogue systems (e.g. Chat-bots) have made great progress during the last years, mainly because of the invention of novel neural models and machine learning techniques. Because of the progress, current research aims to improve the dialogue systems on an individual and human-like level. Recent articles \cite{DBLP:journals/corr/abs-1901-08149, liu2020impress} tried to tackle this problem by feeding a persona into the network. The network is then trained to extract characteristic information from the given persona in order to generate a human-like output sequence. The persona is defined by a set of profile sentences like \textit{I like books}. The problem of these approaches consist of two tasks:
\begin{itemize}
\item \textbf{Persona understanding:}\\
The network needs to understand what the characteristics of the given persona are. This also yields the question on what defines a certain persona and on how to formulate the profile sentences, since the Persona definition has to be done manually. 
\item \textbf{Style derivation:}\\
The network needs to derive a certain speaking/writing style from the given persona. Profile sentences like \textit{I bought my first home} \cite{liu2020impress} do not necessarily contribute to a distinct writing style.
\end{itemize}
An alternative approach is to extract the style in an abstract representation from given context sentences in order to infuse the style in the response generation process of a dialogue agent. With the ability to extract style from an arbitrary context we are able to create the context automatically or let it be generated by the user, thereby we do not need hand crafted pre-defined styles but are able to react to a style more dynamically. A recent attempt called TextSETTR \cite{riley2020textsettr} have been made to perform abstract style extraction from an arbitrary context. An additional advantage of \cite{riley2020textsettr} is that they use a collection of self supervised train task in order to train TextSETTR. This enables the possibility to easily generate a large amount of suitable data and moreover, consider a significantly larger variance of different writing style from different sources. 
The idea in \cite{riley2020textsettr} is not to extract all the information from the given context that define the respective style but only to detect a certain style and 

A common dialogue agent consists of three 
\section{Theory}

Traditionally, a goal oriented dialogue agent consists of three components a (1) \textit{natural language understanding} unit (NLU), a (2) dialogue management unit and a (3) \textit{natural language generation} unit (NLG). The NLU unit extracts information from the dialogue and presents them in a predefined format by slot filling. The dialogue management unit contains a state tracker that keeps track of the dialogue history as well as the user goal. Together with the user goal and the extracted information we can then query additional data from a database. Based on the previous information the dialogue management then decides the next action with a learned policy. The NLG unit then generates the systems response conditioned on the previous information and the next action.\\
Training these units can be quite labour intensive. All units have to be trained individually. Specifically, the policy function of the dialogue management unit requires a lot of additional work. Usually, the policy function is trained via reinforcement learning \cite{DBLP:journals/ml/Williams92}. Since a dialogue is a non-deterministic environment the reinforcement signal has to be generate by a human, which can be quite time intensive. Recent work has shown that this work can be reduce by introducing a trainable model that tries to generate the reinforcement signal automatically \cite{DBLP:journals/corr/abs-1907-00448}. However, this approach still requires at least some human interaction in order to train the model that should generate the signal.\\
Due to recent progress in sequence-to-sequence (seq2seq) models \cite{radford2019language, raffel2019exploring} recent work tries to fuse the NLU, dialogue management and NLG units into one seq2seq model. 
\section{Experimental Setup}

\lipsum[4-5]

\section{Results}

\lipsum[6]

\section{Conclusions}

\lipsum[7]

\section*{Acknowledgements}

\lipsum[8]

\bibliographystyle{IEEEtran}
\bibliography{literature}

\end{document}
